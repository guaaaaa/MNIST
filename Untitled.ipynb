{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee3d2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "0.18.1\n",
      "1.26.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'tqdm' from '/Users/5523833/anaconda3/envs/tf/lib/python3.9/site-packages/tqdm/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataset, normalize, models, loss_optimizer\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(np.__version__)\n",
    "tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b21dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded\n",
      "Training set length: 60000\n",
      "Test set length: 10000\n",
      "Labels: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
      "Train dataloader: 1875 batches of 32\n",
      "Device: cpu\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1289384c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import dataset, engine, info, normalize, models, loss_optimizer, utils\n",
    "\n",
    "train_data, test_data = dataset.dataset()\n",
    "if train_data is None or test_data is None:\n",
    "    raise Exception('Error downloading the dataset')\n",
    "    \n",
    "info.info(train_data, test_data)\n",
    "\n",
    "train_data_normal, test_data_normal = normalize.normalize(train_data, test_data, 32)\n",
    "\n",
    "device = utils.device()\n",
    "\n",
    "model = models.MNIST_CNN().to(device)\n",
    "\n",
    "loss_fn, optimizer = loss_optimizer.loss_optimizer(model, 0.01)\n",
    "print(test_data_normal)\n",
    "engine.train(model=model, train_dataloader=train_data_normal, test_dataloader=test_data_normal, loss_fn=loss_fn, optimizer=optimizer, epochs=3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7edd1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model as python pickle object\n",
    "from pathlib import Path\n",
    "\n",
    "# Create model directory path\n",
    "MODEL_PATH = Path(\"cnn_model\")\n",
    "\n",
    "# Make a directory in collab environment\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create model\n",
    "MODEL_NAME = \"cnn_model.pth\"\n",
    "\n",
    "# Create model save path\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "print(MODEL_SAVE_PATH)\n",
    "\n",
    "# Save model (only the state dictionaries)\n",
    "torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea68d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "def make_pred(model, test_data, device, n=9):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        for i in range(n):\n",
    "            rand_int = torch.randint(0, len(test_data) - n, size=[1]).item()\n",
    "            image, label = test_data[rand_int]\n",
    "            image = image.unsqueeze(dim=0).to(device)\n",
    "\n",
    "          # Show image first\n",
    "            fig.add_subplot(3, 3, i+1)\n",
    "            plt.imshow(image.squeeze().cpu(),cmap='gray')\n",
    "\n",
    "          # Then normalize for prediction\n",
    "            mu = image.mean()\n",
    "            std = image.std()\n",
    "            image = (image - mu)/ image.std()\n",
    "            pred = model(image)\n",
    "\n",
    "            if pred.argmax(dim=1).item() == label:\n",
    "                plt.title(f'Label: {label} | Pred: {pred.argmax(dim=1).item()}', c='g')\n",
    "            else:\n",
    "                plt.title(f'Label: {label} | Pred: {pred.argmax(dim=1).item()}', c='r')\n",
    "            plt.axis('off')\n",
    "\n",
    "make_pred(model, test_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeafc534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset\n\u001b[1;32m      3\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m dataset()\n\u001b[0;32m----> 4\u001b[0m X, y \u001b[38;5;241m=\u001b[39m test_data\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from dataset import dataset\n",
    "\n",
    "train_data, test_data = dataset()\n",
    "X, y = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62798985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
